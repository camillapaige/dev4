{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f89af0",
   "metadata": {},
   "source": [
    "Camilla Green 5/16/25\n",
    "\n",
    "# Asana Task and Attachment Export Script\n",
    "This script uses the Asana API to access tasks, subtasks, and attachments. The script retrieves tasks and subtasks from all of the projects that the user has access to, extracts their details, and saves them to a CSV file. It also retrieves attachments for each task. The output of the script is saved to the same location as the script itself. The script creates a folder \"attachments\". Each project has a folder inside \"attachments,\" and each task has a folder inside the project folder which contains the associated attachments. The script also creates a log file of any projects that were skipped. For the use case of the GRID3 team, all of the projects that the user has access to will be downloaded. Due to the large file size, projects will be processed in batches of 25. The script zips all of the output into one zip file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e86a2f",
   "metadata": {},
   "source": [
    "To summarize, the output will look like:\n",
    "attachments.zip \n",
    "Inside:\n",
    "/attachments/<project_name>/<task_name>/<attachment_name.extension>\n",
    "The csv is named <project_name>_export.csv, is inside <project_name> folder, and contains fields for all of the tasks and subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6765b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f26c0",
   "metadata": {},
   "source": [
    "First get your asana pat from here:\n",
    "https://app.asana.com/0/my-apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pat - personal access token\n",
    "#REPLACE THIS WITH YOUR OWN TOKEN\n",
    "PAT = \"TOKEN HERE\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {PAT}\"\n",
    "}\n",
    "#print info about owner of api token\n",
    "response = requests.get(\"https://app.asana.com/api/1.0/users/me\", headers=headers)\n",
    "print(response.json())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b56ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will determine if the user is authenticated and print the user if it is successful\n",
    "def verify_authentication():\n",
    "    response = requests.get(\"https://app.asana.com/api/1.0/users/me\", headers=headers)\n",
    "    user = response.json().get(\"data\", {}).get(\"name\", \"Unknown\")\n",
    "    print(f\"üîê Authenticated as: {user}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fac294",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_authentication()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1fefa",
   "metadata": {},
   "source": [
    "This will list all the asana projects so you can get the relevant project id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {PAT}\"\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://app.asana.com/api/1.0/projects\", headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f36a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will get info on all projects accessible by the authenticated user\n",
    "def get_all_accessible_projects():\n",
    "    projects = {}\n",
    "    # First get workspaces\n",
    "    workspaces_url = \"https://app.asana.com/api/1.0/workspaces\"\n",
    "    workspaces_response = requests.get(workspaces_url, headers=headers)\n",
    "    workspaces = workspaces_response.json().get(\"data\", [])\n",
    "\n",
    "    # Then get projects in each workspace\n",
    "    for ws in workspaces:\n",
    "        workspace_gid = ws[\"gid\"]\n",
    "        workspace_name = ws[\"name\"]\n",
    "        print(f\"üîç Scanning projects in workspace: {workspace_name}\")\n",
    "        projects_url = f\"https://app.asana.com/api/1.0/projects?workspace={workspace_gid}&archived=false\"\n",
    "        while projects_url:\n",
    "            proj_response = requests.get(projects_url, headers=headers)\n",
    "            proj_data = proj_response.json().get(\"data\", [])\n",
    "            for p in proj_data:\n",
    "                projects[p[\"name\"]] = p[\"gid\"]\n",
    "            projects_url = proj_response.json().get(\"next_page\", {}).get(\"uri\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\n Total projects added: {len(projects)}\")\n",
    "    return projects\n",
    "\n",
    "\n",
    "# Replace hardcoded dictionary:\n",
    "projects = get_all_accessible_projects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create batches of 25 projects to process at a time\n",
    "def batch_projects(projects_dict, batch_size=25):\n",
    "    items = list(projects_dict.items())\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        yield dict(items[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "# get project name from Asana API using its GID - this is used to create a folder for the project\n",
    "def get_project_name(project_gid):\n",
    "    \"\"\"Get the project name from Asana API using its GID.\"\"\"\n",
    "    url = f\"https://app.asana.com/api/1.0/projects/{project_gid}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()[\"data\"].get(\"name\", \"asana_project\")\n",
    "\n",
    "#clean the name of the project to make it a valid folder name\n",
    "#this is done by replacing invalid characters with underscores\n",
    "def clean_filename(name):\n",
    "    \"\"\"Sanitize file and folder names.\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name.replace(\" \", \"_\"))\n",
    "\n",
    "#create a folder for the project with the project name from asana,\n",
    "#this folder will go inside the folder named \"attachments\" \n",
    "def create_output_folder(project_gid, base_path=\"attachments\"):\n",
    "    project_name = clean_filename(get_project_name(project_gid))\n",
    "    folder_name = f\"{project_name}\"\n",
    "    output_path = os.path.join(base_path, folder_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    return output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfabe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task and Metadata Export\n",
    "#get all tasks for a project\n",
    "def get_all_tasks(project_gid):\n",
    "    tasks = []\n",
    "    url = f\"https://app.asana.com/api/1.0/projects/{project_gid}/tasks\"\n",
    "    params = {\"opt_fields\": \"name,completed,assignee.name,due_on,notes,custom_fields\"}\n",
    "    while url:\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        tasks.extend(r.json().get(\"data\", []))\n",
    "        url = r.json().get(\"next_page\", {}).get(\"uri\")\n",
    "    return tasks\n",
    "\n",
    "#get all subtasks for each task\n",
    "def get_subtasks_for_task(task_gid):\n",
    "    subtasks = []\n",
    "    url = f\"https://app.asana.com/api/1.0/tasks/{task_gid}/subtasks\"\n",
    "    params = {\"opt_fields\": \"name,completed\"}\n",
    "    while url:\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        subtasks.extend(r.json().get(\"data\", []))\n",
    "        url = r.json().get(\"next_page\", {}).get(\"uri\")\n",
    "    return subtasks\n",
    "\n",
    "#get stories (comments and system history/events) for each task and subtask\n",
    "def get_stories_for_task(task_gid):\n",
    "    stories = []\n",
    "    url = f\"https://app.asana.com/api/1.0/tasks/{task_gid}/stories\"\n",
    "    while url:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        for s in r.json().get(\"data\", []):\n",
    "            created_by = s.get(\"created_by\")\n",
    "            author = created_by[\"name\"] if created_by else \"System\"\n",
    "            stories.append({\n",
    "                \"type\": s.get(\"type\"),\n",
    "                \"resource_subtype\": s.get(\"resource_subtype\"),\n",
    "                \"author\": author,\n",
    "                \"created_at\": s.get(\"created_at\"),\n",
    "                \"text\": s.get(\"text\", \"\")\n",
    "            })\n",
    "        url = r.json().get(\"next_page\", {}).get(\"uri\")\n",
    "    return stories\n",
    "\n",
    "#format stories (comments) into a single string so they can be written to a csv as 1 field\n",
    "def flatten_stories(stories):\n",
    "    return \" | \".join(\n",
    "        f\"[{s['created_at']}] {s['author']} ({s['resource_subtype']}): {s['text']}\"\n",
    "        for s in stories\n",
    "    )\n",
    "\n",
    "#format subtasks into a single string so they can be written to a csv as 1 field\n",
    "def flatten_subtasks(subtasks):\n",
    "    lines = []\n",
    "    for s in subtasks:\n",
    "        name = s['name']\n",
    "        completed = s['completed']\n",
    "        stories = get_stories_for_task(s['gid'])\n",
    "        story_text = flatten_stories(stories)\n",
    "        lines.append(f\"{name} (Completed: {completed}) - Stories: [{story_text}]\")\n",
    "    return \" | \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the project data to a csv file\n",
    "def export_project_data_to_csv(project_gid, output_folder, log_file=\"skipped_projects.log\"):\n",
    "    \"\"\"Export full task data to a CSV file or log if no tasks found.\"\"\"\n",
    "    project_name = clean_filename(get_project_name(project_gid))\n",
    "    output_file = os.path.join(output_folder, f\"{project_name}_export.csv\")\n",
    "    tasks = get_all_tasks(project_gid)\n",
    "    all_task_data = []\n",
    "\n",
    "    for task in tasks:\n",
    "        subtasks = get_subtasks_for_task(task[\"gid\"])\n",
    "        stories = get_stories_for_task(task[\"gid\"])\n",
    "        task_data = {\n",
    "            \"Task GID\": task[\"gid\"],\n",
    "            \"Name\": task.get(\"name\", \"[No name]\"),\n",
    "            \"Completed\": task.get(\"completed\"),\n",
    "            \"Assignee\": task.get(\"assignee\", {}).get(\"name\", \"Unassigned\") if task.get(\"assignee\") else \"Unassigned\",\n",
    "            \"Due On\": task.get(\"due_on\") or \"No due date\",\n",
    "            \"Notes\": task.get(\"notes\") or \"No notes\",\n",
    "            \"Custom Fields\": \", \".join([\n",
    "                f\"{f.get('name')}: {f.get('text_value') or f.get('number_value') or (f.get('enum_value') or {}).get('name', '')}\"\n",
    "                for f in task.get(\"custom_fields\", []) if f\n",
    "            ]),\n",
    "            \"Subtasks\": flatten_subtasks(subtasks),\n",
    "            \"Stories\": flatten_stories(stories)\n",
    "        }\n",
    "        all_task_data.append(task_data)\n",
    "\n",
    "    if not all_task_data:\n",
    "        msg = f\"{project_name} (GID: {project_gid}) - Skipped: No tasks found\\n\"\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(msg)\n",
    "        print(f\"‚ö†Ô∏è {msg.strip()}\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=all_task_data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_task_data)\n",
    "\n",
    "    print(f\"üìÑ Exported {len(all_task_data)} tasks to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access attachments for each project, process each task and download into folders based on task name\n",
    "def get_attachments_for_task(task_gid):\n",
    "    attachments = []\n",
    "    url = f\"https://app.asana.com/api/1.0/tasks/{task_gid}/attachments\"\n",
    "    while url:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        attachments.extend(r.json().get(\"data\", []))\n",
    "        url = r.json().get(\"next_page\", {}).get(\"uri\")\n",
    "    return attachments\n",
    "\n",
    "#get the download URL for each attachement\n",
    "def get_download_url(attachment_gid):\n",
    "    url = f\"https://app.asana.com/api/1.0/attachments/{attachment_gid}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    return r.json().get(\"data\", {}).get(\"download_url\") if r.status_code == 200 else None\n",
    "\n",
    "#download all attachments for each task in the project, log if no tasks exist\n",
    "def download_all_attachments(project_gid, base_folder, log_file=\"skipped_projects.log\"):\n",
    "    tasks = get_all_tasks(project_gid)\n",
    "\n",
    "    if not tasks:\n",
    "        project_name = clean_filename(get_project_name(project_gid))\n",
    "        msg = f\"{project_name} (GID: {project_gid}) - Skipped: No tasks for attachment download\\n\"\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(msg)\n",
    "        print(f\"‚ö†Ô∏è {msg.strip()}\")\n",
    "        return\n",
    "\n",
    "    for task in tasks:\n",
    "        task_gid = task[\"gid\"]\n",
    "        task_name = clean_filename(task.get(\"name\", \"untitled_task\"))\n",
    "        task_folder = os.path.join(base_folder, f\"{task_name}\")\n",
    "        os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "        attachments = get_attachments_for_task(task_gid)\n",
    "        for att in attachments:\n",
    "            url = get_download_url(att[\"gid\"]) or att.get(\"permalink_url\")\n",
    "            if not url:\n",
    "                print(f\"‚ö†Ô∏è Skipping {att['name']}: no download URL\")\n",
    "                continue\n",
    "            try:\n",
    "                print(f\"‚¨áÔ∏è Downloading {att['name']} to {task_folder}...\")\n",
    "                r = requests.get(url, stream=True)\n",
    "                if r.status_code == 200:\n",
    "                    file_path = os.path.join(task_folder, clean_filename(att[\"name\"]))\n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        for chunk in r.iter_content(1024):\n",
    "                            f.write(chunk)\n",
    "                    print(f\"‚úÖ Saved to {file_path}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed to download {att['name']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error downloading {att['name']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will zip the folder containing all the attachments into \"attachments.zip\" \n",
    "def zip_folder(folder_path, zip_name=None, delete_original=False):\n",
    "    #If you want to delete the original folder after zipping, set delete_original=True.\n",
    "    if not zip_name:\n",
    "        zip_name = folder_path + \".zip\"\n",
    "\n",
    "    print(f\"üóúÔ∏è Zipping folder '{folder_path}' to '{zip_name}'...\")\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED, allowZip64=True) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, start=folder_path)\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as fsrc:\n",
    "                        zipf.writestr(arcname, fsrc.read())  # reads small chunks internally\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {file_path} due to error: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Zip created: {zip_name}\")\n",
    "\n",
    "    if delete_original:\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"üßπ Deleted original folder: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Main Loop to process tasks, subtasks, and attachments\n",
    "#this processes all projects in the dictionary in batches and creates a folder for each project\n",
    "# It will zip the attachments folder at the end\n",
    "def process_all_projects(projects, combined_output_root=\"attachments\", combined_zip_name=\"attachments.zip\"):\n",
    "    os.makedirs(combined_output_root, exist_ok=True)\n",
    "    verify_authentication() \n",
    "    for batch_num, project_batch in enumerate(batch_projects(projects, batch_size=25), start=1):\n",
    "        print(f\"\\nüì¶ Starting Batch {batch_num} (processing {len(project_batch)} projects)...\")\n",
    "        for name, gid in project_batch.items():\n",
    "            print(f\"\\nProcessing Project: {name}\")\n",
    "            project_folder = create_output_folder(gid, base_path=combined_output_root)\n",
    "            export_project_data_to_csv(gid, project_folder)\n",
    "            download_all_attachments(gid, project_folder)\n",
    "\n",
    "    # üîö Create one zip from the full attachments directory\n",
    "    zip_folder(combined_output_root, combined_zip_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run everything\n",
    "#this will process all the projects listed in the dictionary, providing a csv file and a folder with attachments for each project\n",
    "#the csv file will be named <project_name>_export.csv and have all the tasks, subtasks, and their metadata\n",
    "#the attachments will be downloaded into folders named after the tasks\n",
    "process_all_projects(projects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asana-mig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
